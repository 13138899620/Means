1.扩容主要分为Scale Up和Scale Out两种，分别对应着增强单个服务的服务能力以及增强服务数量。
Scale Up是一个较为简单的操作，例如为该服务所在的服务器添加更大的内存。但是任意一个服务器所能提供的能力实际上都受到其自身物理硬件能力的限制，尤其是具有越高性能的服务器其单位服务能力的价格越为昂贵，
因此我们就需要使用Scale  Out方式将工作量分摊到多个服务器之中：


2.我们需要使用一台特定的设备将这些请求分发到各个服务器。该设备会根据其内部所包含的请求分发逻辑来决定如何对这些请求进行分发，以避免出现单个服务器过载的情况。
这些用来对请求进行分发的设备实际上就是负载平衡服务器。

3.L3/4负载平衡服务器拥有很高的性能，因此一般的服务所使用的负载平衡系统不会遇到需要扩展性的问题。
但是一旦出现了需要扩展的情况，那么使用DNS负载平衡就可以达到较好的扩展性。
而L7负载平衡则更为灵活，因此扩展性更不是问题。

4.DNS负载均衡
不同的DNS请求所返回的结果会按照Round Robin进行轮换，进而使得不同的用户访问不同的IP地址，平衡各个服务器的负载。
DNS的负载平衡方案并不能作为一个独立的负载平衡解决方案来提供高可用性的保障，而是作为其它负载平衡解决方案的补充方案来使用。

5.L3/4负载均衡 
L3/4实际上指的就是负载平衡服务器会根据OSI模型中的第三层网络层（Network Layer）和第四层传输层（Transport Layer）所包含的数据来进行负载平衡操作。在这种负载平衡服务器中，这些数据主要包含数据包的IP头和TCP、UDP等协议的协议头
数据到达时，负载平衡服务器将根据自身算法以及OSI模型三四层所包含的数据决定需要处理该数据的服务实例并将其转发。

负载平衡服务器需要知道当前有效的服务实例到底有哪些，并根据自身的分派算法来决定需要处理数据的服务实例，根据分派算法的计算结果将数据发送到目标服务实例上。
，Round Robin算法是最常用也是表现最好的负载平衡算法。如果各个服务实例的容量并不相同，那么负载平衡服务器会使用Weighted Round Robin算法，即根据各个服务实例的实际能力来安比例地分配负载。在某些商业负载平衡服务器中，
其的确会根据当前服务实例的负载以及响应时间等因素对这些分配比例自动进行微小地调整，但是它们并不是决定性的因素。

6.L7负载平衡
L7负载平衡服务器上的操作系统会将接收到的各个数据包组织成为用户请求，并根据在该请求中所包含的的数据来决定由哪个服务实例来对该请求进行处理。